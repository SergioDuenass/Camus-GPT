{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img style=\"float: left; margin: 30px 15px 15px 15px;\" src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTFzQj91sOlkeDFkg5HDbjtR4QJYmLXkfMNig&usqp=CAU\" width=\"400\" height=\"200\" />\n",
        "    \n",
        "    \n",
        "## <font color='Black'> Deep Learning.\n",
        "\n",
        "###Proyecto 1 - Autoencoders.\n",
        "\n",
        "**Nombre:** Sergio Daniel Dueñas Godinez.\n",
        "\n",
        "**Expediente** : 739300.\n",
        "    \n",
        "**Profesor:** Iván Reyes Amezcua.\n",
        "    \n",
        "**Link Github**: https://github.com/SergioDuenass/Camus-GPT"
      ],
      "metadata": {
        "id": "T-tZAlIX1_O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivos:\n",
        "\n",
        "    Comprender los principios fundamentales de los autoencoders y su aplicación en deep learning generativo.\n",
        "    Implementar un autoencoder básico y variacionales para una tarea específica, como reducción de dimensión, denoising o generación de imágenes.\n",
        "    Analizar el rendimiento y las características de las representaciones aprendidas por los autoencoders.\n",
        "\n",
        "\n",
        "Descripción\n",
        "\n",
        "    Deberán seleccionar un conjunto de datos adecuado para su proyecto, que puede ser de imágenes, texto o cualquier otro tipo que permita la aplicación de autoencoders.\n",
        "    Implementar un autoencoder, como un variacional (VAE) o un autoencoder convolucional, dependiendo de la naturaleza del conjunto de datos y el objetivo del proyecto.\n",
        "    El proyecto incluirá una fase de experimentación donde los deberán entrenar, ajustar y evaluar sus modelos.\n",
        "    Presentar sus resultados a través de un informe escrito y una presentación, discutir la implementación, los desafíos encontrados, el rendimiento de sus modelos y las aplicaciones potenciales de su trabajo.\n"
      ],
      "metadata": {
        "id": "3kG-9uK9_xgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Los datos fueron recopliados de los libros de Camus; 'El Extranjero' y 'La Plaga'"
      ],
      "metadata": {
        "id": "BcoSq5x-_y5f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NIDWbWBxA7nk"
      },
      "outputs": [],
      "source": [
        "# Librerias a utilizar\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import binary_crossentropy, mean_squared_error\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv1D, Conv1DTranspose, Lambda\n",
        "\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th0BLMthBUmH",
        "outputId": "6cec3130-7136-4ee4-ad57-10311b64c3dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRqQa_V3A7nk"
      },
      "source": [
        "### Tokenización, embeddings y limpieza de corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h2qRWWZAA7nl"
      },
      "outputs": [],
      "source": [
        "def clean_corpus_from_file(file_path):\n",
        "    cleaned_corpus = []\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            # Leer el contenido del archivo\n",
        "            corpus = file.readlines()\n",
        "\n",
        "            for text in corpus:\n",
        "                # Convertir a minúsculas\n",
        "                text = text.lower()\n",
        "\n",
        "                # Eliminar caracteres no alfabéticos y números\n",
        "                text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "                # Eliminar espacios en blanco adicionales\n",
        "                text = ' '.join(text.split())\n",
        "\n",
        "                cleaned_corpus.append(text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "\n",
        "    return cleaned_corpus\n",
        "\n",
        "\n",
        "\n",
        "def clean_corpus(corpus):\n",
        "    cleaned_corpus = []\n",
        "\n",
        "    for text in corpus:\n",
        "        # Convertir a minúsculas\n",
        "        text = text.lower()\n",
        "\n",
        "        # Eliminar caracteres no alfabéticos y números\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "        # Eliminar espacios en blanco adicionales\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        cleaned_corpus.append(text)\n",
        "\n",
        "    return cleaned_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "px1WrZF_A7nm"
      },
      "outputs": [],
      "source": [
        "# Utilizo spacy para la tokenización\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def tokenize_corpus(corpus):\n",
        "    tokenized_corpus = []\n",
        "\n",
        "    for text in corpus:\n",
        "        # Tokenizar el texto usando spaCy\n",
        "        tokens = [token.text for token in nlp(text)]\n",
        "        tokenized_corpus.append(tokens)\n",
        "\n",
        "    return tokenized_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hQDB4Uz-A7nm"
      },
      "outputs": [],
      "source": [
        "corpus_file_path = \"/content/drive/MyDrive/ProyectoCamus/data/corpus.txt\"\n",
        "cleaned_corpus = clean_corpus_from_file(corpus_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "592vOODKA7nm"
      },
      "outputs": [],
      "source": [
        "tokenized_corpus = tokenize_corpus(cleaned_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AedYRZ6GA7nn",
        "outputId": "d0e39cad-a089-48e1-b104-ee7f7d271796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus Padded Shape: (8289, 106)\n",
            "Embedded Sequence Shape: (8289, 106, 300)\n"
          ]
        }
      ],
      "source": [
        "# Construir un vocabulario\n",
        "vocabulario = {token: idx for idx, token in enumerate(set(token for sublist in tokenized_corpus for token in sublist))}\n",
        "vocab_size = len(vocabulario)\n",
        "\n",
        "# Convertir tokens a índices\n",
        "corpus_indices = [[vocabulario[token] for token in secuencia] for secuencia in tokenized_corpus]\n",
        "\n",
        "# Padding de las secuencias\n",
        "corpus_padded = pad_sequences(corpus_indices, padding='post', truncating='post')\n",
        "\n",
        "# Crear el modelo de embedding\n",
        "embedding_dim = 300  # ajusta según tus necesidades\n",
        "embedding_model = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "\n",
        "# Obtener vectores de embedding\n",
        "embedded_sequence = embedding_model(corpus_padded)\n",
        "\n",
        "# Ver la salida\n",
        "print(\"Corpus Padded Shape:\", corpus_padded.shape)\n",
        "print(\"Embedded Sequence Shape:\", embedded_sequence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RcuSco-A7nn"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdrnWe-A7no",
        "outputId": "b2edde66-cd4d-49ef-fe0d-b6aa21195498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8289, 106, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "embedded_sequence.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BT1PbKdBA7no"
      },
      "outputs": [],
      "source": [
        "input_shape = embedded_sequence.shape[1:]\n",
        "batch_size = 128\n",
        "latent_dim = 64\n",
        "epochs = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuAvKLE-A7no"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rhF9wEF0A7np"
      },
      "outputs": [],
      "source": [
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "\n",
        "  dim = K.int_shape(z_mean)[1]\n",
        "\n",
        "  # TODO: check dimensions\n",
        "  epsilon = K.random_normal(shape = (K.shape(z_mean)[0], dim))\n",
        "\n",
        "  return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de capa de muestreo utilizando reparameterization trick\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "UZyLamOV8zgP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar las dimensiones de las secuencias de entrada\n",
        "target_length_input = 106\n",
        "corpus_padded_input = pad_sequences(corpus_indices, maxlen=target_length_input, padding='post', truncating='post')\n",
        "\n",
        "# Convertir a embeddings\n",
        "embedded_sequence_input = embedding_model(corpus_padded_input)\n",
        "\n",
        "# Ajustar las dimensiones de las secuencias de salida\n",
        "target_length_output = 106\n",
        "corpus_padded_output = pad_sequences(corpus_indices, maxlen=target_length_output, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "# Convertir a embeddings\n",
        "embedded_sequence_output = embedding_model(corpus_padded_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "F8XmlzCj1Tvy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_sequence_input.shape, embedded_sequence_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oVLZQm7BWU7",
        "outputId": "61eeace8-7425-4b91-f3d3-a05a5ef85b22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([8289, 106, 300]), TensorShape([8289, 106, 300]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6X34REy2A7ns"
      },
      "outputs": [],
      "source": [
        "# Ajustar el modelo Encoder\n",
        "input_shape_encoder = (target_length_output, embedding_dim)  # Ajusta según tus necesidades\n",
        "latent_dim = 32  # Ajusta según tus necesidades\n",
        "\n",
        "inputs_encoder = Input(shape=input_shape_encoder, name=\"encoder_input\")\n",
        "x_encoder = Conv1D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(inputs_encoder)\n",
        "x_encoder = Conv1D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x_encoder)\n",
        "\n",
        "shape_before_flat_encoder = K.int_shape(x_encoder)\n",
        "x_encoder = Flatten()(x_encoder)\n",
        "x_encoder = Dense(256, activation=\"relu\", kernel_initializer='he_normal')(x_encoder)\n",
        "\n",
        "z_mean_encoder = Dense(latent_dim, name='z_mean')(x_encoder)\n",
        "z_log_var_encoder = Dense(latent_dim, name='z_log_var')(x_encoder)\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean_encoder, z_log_var_encoder])\n",
        "\n",
        "encoder = Model(inputs_encoder, [z_mean_encoder, z_log_var_encoder], name='encoder')\n",
        "\n",
        "#\n",
        "target_length_output = 106\n",
        "embedding_dim = 300\n",
        "\n",
        "# Definir el modelo Decoder\n",
        "latent_inputs_decoder = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x_decoder = Dense(np.prod(shape_before_flat_encoder[1:]), activation=\"relu\", kernel_initializer='he_normal')(latent_inputs_decoder)\n",
        "x_decoder = Reshape(shape_before_flat_encoder[1:])(x_decoder)\n",
        "\n",
        "# Usar Conv1DTranspose con padding='same' para ajustar la longitud de salida\n",
        "x_decoder = Conv1DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x_decoder)\n",
        "x_decoder = Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x_decoder)\n",
        "\n",
        "# Ajustar manualmente la longitud de la salida a target_length_output\n",
        "outputs_decoder = Conv1DTranspose(embedding_dim, 3, activation=\"linear\", padding=\"same\")(x_decoder)\n",
        "outputs_decoder = outputs_decoder[:, :target_length_output, :]\n",
        "\n",
        "# Definir el modelo Decoder\n",
        "decoder = Model(latent_inputs_decoder, outputs_decoder, name='decoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5coZEJpHB9Kj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE\n",
        "outputs_vae = decoder(encoder(inputs_encoder)[0])\n",
        "vae = Model(inputs_encoder, outputs_vae, name='vae')\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "# reconstruction_loss = mean_squared_error(K.flatten(inputs), K.flatten(outputs) * input_shape[0] * input_shape[1])\n",
        "reconstruction_loss = mean_squared_error(K.flatten(inputs_encoder), K.flatten(outputs_vae))\n",
        "\n",
        "kl_loss = 1 + z_mean_encoder - K.square(z_mean_encoder) - K.exp(z_log_var_encoder)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvclT33hUFaI",
        "outputId": "c7ad4c2d-3a53-4407-acfe-4b24d920a406"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 106, 300)]           0         []                            \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 32),                 494112    ['encoder_input[0][0]']       \n",
            "                              (None, 32)]                                                         \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, 106, 300)             104652    ['encoder[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 53, 32)               28832     ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 27, 64)               6208      ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 1728)                 0         ['conv1d_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  442624    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 32)                   8224      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 32)                   0         ['z_mean[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda  (None, 32)                   0         ['z_mean[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 32)                   8224      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)   (None,)                      0         ['decoder[0][0]']             \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None,)                      0         ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLamb  (None, 32)                   0         ['tf.__operators__.add[0][0]',\n",
            " da)                                                                 'tf.math.square[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)    (None, 32)                   0         ['z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOp  (None,)                      0         ['tf.reshape_1[0][0]']        \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)        (None,)                      0         ['tf.reshape[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLa  (None, 32)                   0         ['tf.math.subtract[0][0]',    \n",
            " mbda)                                                               'tf.math.exp[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.squared_difference  (None,)                      0         ['tf.convert_to_tensor[0][0]',\n",
            "  (TFOpLambda)                                                       'tf.cast[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLa  (None,)                      0         ['tf.math.subtract_1[0][0]']  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpL  ()                           0         ['tf.math.squared_difference[0\n",
            " ambda)                                                             ][0]']                        \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLamb  (None,)                      0         ['tf.math.reduce_sum[0][0]']  \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None,)                      0         ['tf.math.reduce_mean[0][0]', \n",
            " OpLambda)                                                           'tf.math.multiply[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFO  ()                           0         ['tf.__operators__.add_1[0][0]\n",
            " pLambda)                                                           ']                            \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)          ()                           0         ['tf.math.reduce_mean_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 598764 (2.28 MB)\n",
            "Trainable params: 598764 (2.28 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Entrenar el modelo\n",
        "vae.fit(embedded_sequence_input, embedded_sequence_output, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRJ8lfnaUBSU",
        "outputId": "37b01cf8-df80-430c-af05-c6e3085422dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "65/65 [==============================] - 23s 321ms/step - loss: -17.5331\n",
            "Epoch 2/30\n",
            "65/65 [==============================] - 19s 296ms/step - loss: -19.9956\n",
            "Epoch 3/30\n",
            "65/65 [==============================] - 20s 314ms/step - loss: -19.9973\n",
            "Epoch 4/30\n",
            "65/65 [==============================] - 19s 296ms/step - loss: -19.9971\n",
            "Epoch 5/30\n",
            "65/65 [==============================] - 19s 293ms/step - loss: -19.9959\n",
            "Epoch 6/30\n",
            "65/65 [==============================] - 20s 315ms/step - loss: -19.9959\n",
            "Epoch 7/30\n",
            "65/65 [==============================] - 18s 279ms/step - loss: -19.9962\n",
            "Epoch 8/30\n",
            "65/65 [==============================] - 18s 278ms/step - loss: -19.9960\n",
            "Epoch 9/30\n",
            "65/65 [==============================] - 20s 306ms/step - loss: -19.9950\n",
            "Epoch 10/30\n",
            "65/65 [==============================] - 19s 293ms/step - loss: -19.9969\n",
            "Epoch 11/30\n",
            "65/65 [==============================] - 18s 274ms/step - loss: -19.9960\n",
            "Epoch 12/30\n",
            "65/65 [==============================] - 19s 296ms/step - loss: -19.9947\n",
            "Epoch 13/30\n",
            "65/65 [==============================] - 19s 293ms/step - loss: -19.9977\n",
            "Epoch 14/30\n",
            "65/65 [==============================] - 19s 300ms/step - loss: -19.9960\n",
            "Epoch 15/30\n",
            "65/65 [==============================] - 20s 305ms/step - loss: -19.9922\n",
            "Epoch 16/30\n",
            "65/65 [==============================] - 19s 293ms/step - loss: -19.9984\n",
            "Epoch 17/30\n",
            "65/65 [==============================] - 21s 318ms/step - loss: -19.9970\n",
            "Epoch 18/30\n",
            "65/65 [==============================] - 19s 293ms/step - loss: -19.9971\n",
            "Epoch 19/30\n",
            "65/65 [==============================] - 20s 307ms/step - loss: -19.9961\n",
            "Epoch 20/30\n",
            "65/65 [==============================] - 20s 310ms/step - loss: -19.9944\n",
            "Epoch 21/30\n",
            "65/65 [==============================] - 19s 294ms/step - loss: -19.9975\n",
            "Epoch 22/30\n",
            "65/65 [==============================] - 21s 320ms/step - loss: -19.9977\n",
            "Epoch 23/30\n",
            "65/65 [==============================] - 19s 289ms/step - loss: -19.9983\n",
            "Epoch 24/30\n",
            "65/65 [==============================] - 20s 301ms/step - loss: -19.9918\n",
            "Epoch 25/30\n",
            "65/65 [==============================] - 20s 311ms/step - loss: -19.9990\n",
            "Epoch 26/30\n",
            "65/65 [==============================] - 19s 295ms/step - loss: -19.9982\n",
            "Epoch 27/30\n",
            "65/65 [==============================] - 25s 392ms/step - loss: -19.9963\n",
            "Epoch 28/30\n",
            "65/65 [==============================] - 18s 284ms/step - loss: -19.9992\n",
            "Epoch 29/30\n",
            "65/65 [==============================] - 20s 306ms/step - loss: -19.9973\n",
            "Epoch 30/30\n",
            "65/65 [==============================] - 19s 287ms/step - loss: -19.9965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2d51509c90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener z_mean, z_log_var\n",
        "z_mean_batch, z_log_var_batch = encoder.predict(embedded_sequence_input)\n",
        "\n",
        "# Utilizar la función de muestreo para generar muestras de la distribución latente\n",
        "latent_samples = sampling([z_mean_batch, z_log_var_batch])\n",
        "\n",
        "# Decodificar las muestras generadas para obtener nuevos embeddings\n",
        "decoded_sentence = decoder.predict(latent_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlSpf2U5UBMM",
        "outputId": "988dde34-fabf-4b41-d728-65824f466f04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260/260 [==============================] - 2s 7ms/step\n",
            "260/260 [==============================] - 4s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cálamos el modelito"
      ],
      "metadata": {
        "id": "pCUR4UBCF3YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el vocabulario inverso\n",
        "inv_vocabulario = {idx: palabra for palabra, idx in vocabulario.items()}"
      ],
      "metadata": {
        "id": "Ps44iaqmFsik"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sequence = []\n",
        "for vector in decoded_sentence[1]:\n",
        "    # Encuentra el índice del token más cercano en el espacio de embedding\n",
        "    idx = np.argmax(vector)\n",
        "    # Convierte el índice a token usando el diccionario inverso\n",
        "    token = inv_vocabulario[idx]\n",
        "    decoded_sequence.append(token)\n",
        "\n",
        "reconstructed_text = ' '.join(decoded_sequence)\n",
        "print(\"Texto reconstruido:\", reconstructed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVncwwRZ8YAg",
        "outputId": "1a1113d2-f702-4e26-8459-cc6dad3dad06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto reconstruido: cinemas cinemas cinemas cinemas cinemas cinemas cinemas cinemas stench planned planned planned planned planned planned t heaving t heaving t t t t t t t t t t t heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving heaving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Malísimo pero lo intentó.\n",
        "\n",
        "Tengo la teoría que el error que me da, es que estoy tratando los outputs del modelo como si fueran de los embeddings que usé pero quizá los vectores que me da no son compatibles, quizá tendría que hacer uno personalizado o no sé."
      ],
      "metadata": {
        "id": "ozgvu7E_F6qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fUiozin2_60",
        "outputId": "a4cb8bcd-dde7-40eb-fdb7-b34d4a366b45"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00342331, -0.0030201 ,  0.00167734, ..., -0.00552389,\n",
              "        -0.00211306,  0.00721318],\n",
              "       [ 0.00342331, -0.0030201 ,  0.00167734, ..., -0.00552389,\n",
              "        -0.00211306,  0.00721318],\n",
              "       [ 0.00342331, -0.0030201 ,  0.00167734, ..., -0.00552389,\n",
              "        -0.00211306,  0.00721318],\n",
              "       ...,\n",
              "       [-0.01326514,  0.016698  ,  0.01247935, ..., -0.04293806,\n",
              "         0.019782  ,  0.00447479],\n",
              "       [-0.01325999,  0.0167598 ,  0.01250423, ..., -0.04318355,\n",
              "         0.01987534,  0.00441948],\n",
              "       [-0.01339806,  0.0168558 ,  0.01251846, ..., -0.04319974,\n",
              "         0.01993513,  0.0044329 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVWEe4UWJ6gW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}