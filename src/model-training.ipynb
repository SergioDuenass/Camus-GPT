{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import log_softmax\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import spacy\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(device)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_corpus_from_file(file_path):\n",
    "    cleaned_corpus = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # Leer el contenido del archivo\n",
    "            corpus = file.readlines()\n",
    "\n",
    "            for text in corpus:\n",
    "                # Convertir a minúsculas\n",
    "                text = text.lower()\n",
    "\n",
    "                # Eliminar caracteres no alfabéticos y números\n",
    "                text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "                # Eliminar espacios en blanco adicionales\n",
    "                text = ' '.join(text.split())\n",
    "\n",
    "                cleaned_corpus.append(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo: {e}\")\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "\n",
    "\n",
    "def clean_corpus(corpus):\n",
    "    cleaned_corpus = []\n",
    "\n",
    "    for text in corpus:\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "\n",
    "        # Eliminar caracteres no alfabéticos y números\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "        # Eliminar espacios en blanco adicionales\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        cleaned_corpus.append(text)\n",
    "\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de spaCy para el idioma correspondiente\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def tokenize_corpus(corpus):\n",
    "    tokenized_corpus = []\n",
    "\n",
    "    for text in corpus:\n",
    "        # Tokenizar el texto usando spaCy\n",
    "        tokens = [token.text for token in nlp(text)]\n",
    "        tokenized_corpus.append(tokens)\n",
    "\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_path = \"data/corpus.txt\"\n",
    "cleaned_corpus = clean_corpus_from_file(corpus_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que 'corpus' es tu corpus de texto\n",
    "tokenized_corpus = tokenize_corpus(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Crear un vocabulario asignando un índice único a cada palabra\n",
    "vocab = {word: idx for idx, word in enumerate(set(word for sent in tokenized_corpus for word in sent))}\n",
    "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "# Convertir tokens a índices numéricos\n",
    "indexed_corpus = [[vocab[word] for word in sent] for sent in tokenized_corpus]\n",
    "\n",
    "# Convertir la lista de listas a tensores\n",
    "input_tensor = pad_sequence([torch.tensor(sentence) for sentence in indexed_corpus], batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 11705\n"
     ]
    }
   ],
   "source": [
    "# Crear un conjunto para almacenar todas las palabras únicas\n",
    "unique_words = set(word for sent in tokenized_corpus for word in sent)\n",
    "\n",
    "# Obtener el tamaño del vocabulario\n",
    "vocab_size = len(unique_words)\n",
    "\n",
    "print(\"Tamaño del vocabulario:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8288, 106])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor[1:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo VAE con generación de texto\n",
    "class VAEWithTextGeneration(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, output_size):\n",
    "        super(VAEWithTextGeneration, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_size * 2)  # Mean and log-variance\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "        self.text_generator = nn.Linear(latent_size, output_size)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
    "\n",
    "        # Reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # Decoder\n",
    "        reconstructed_x = self.decoder(z)\n",
    "\n",
    "        # Text Generation\n",
    "        generated_text = log_softmax(self.text_generator(z), dim=-1)\n",
    "\n",
    "        return reconstructed_x, generated_text, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "input_size = 106 # Tamaño de entrada (ajustar según tus datos)\n",
    "hidden_size = 256 # Tamaño de capa oculta\n",
    "latent_size = 64 # Tamaño de la capa latente\n",
    "output_size = 11705 # Tamaño de salida (vocabulario en el caso de texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo VAE\n",
    "vae = VAEWithTextGeneration(input_size, hidden_size, latent_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Para problemas de clasificación de texto\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del VAE\n",
    "vae.train()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "input_tensor = input_tensor.float()\n",
    "reconstructed_x, generated_text, mu, log_var = vae(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste al mismo tamaño de lote usando relleno (padding)\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "input_tensor_padded = pad_sequence([torch.tensor(sentence) for sentence in indexed_corpus], batch_first=True)\n",
    "flat_target_padded = pad_sequence([torch.tensor(sentence) for sentence in indexed_corpus], batch_first=True)\n",
    "\n",
    "# Aplanar el tensor de etiquetas\n",
    "flat_target = flat_target_padded.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar el tensor de etiquetas\n",
    "flat_target = input_tensor.view(-1)\n",
    "flat_target_reduced = flat_target[:input_tensor.size(0)]\n",
    "\n",
    "\n",
    "flat_target_reduced = flat_target_reduced.long()\n",
    "\n",
    "# Calcular la pérdida\n",
    "reconstruction_loss = criterion(reconstructed_x, flat_target_reduced)\n",
    "generation_loss = criterion(generated_text, flat_target_reduced)\n",
    "kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "total_loss = reconstruction_loss + generation_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass y optimización\n",
    "total_loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataLoader con relleno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ArrayRef: invalid slice, N = 1; size = 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m vae\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     24\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m padded_sequences, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(padded_sequences) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Saltar el lote vacío\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 12\u001b[0m, in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([]), torch\u001b[38;5;241m.\u001b[39mtensor([])  \u001b[38;5;66;03m# Devolver tensores vacíos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Resto del código\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m padded_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded_sequences, torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_39/lib/python3.9/site-packages/torch/nn/utils/rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ArrayRef: invalid slice, N = 1; size = 0"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Modifica tu DataLoader para que el collate_fn maneje las secuencias y las etiquetas por separado\n",
    "def my_collate(batch):\n",
    "    sequences = [torch.tensor(item[0]) for item in batch if item[0]]  # Filtrar secuencias vacías\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    if not sequences:\n",
    "        return torch.tensor([]), torch.tensor([])  # Devolver tensores vacíos\n",
    "\n",
    "    # Resto del código\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, torch.tensor(labels)\n",
    "\n",
    "# DataLoader con el nuevo collate_fn\n",
    "train_loader = DataLoader(indexed_corpus, batch_size=batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# Resto del código sin cambios\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    vae.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for padded_sequences, labels in train_loader:\n",
    "        if len(padded_sequences) == 0:\n",
    "            continue  # Saltar el lote vacío\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Obtener las salidas del modelo\n",
    "        reconstructed_x, generated_text, mu, log_var = vae(padded_sequences)\n",
    "\n",
    "        # Aplanar las etiquetas\n",
    "        flat_target_reduced = labels.view(-1).long()\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        reconstruction_loss = criterion(reconstructed_x, flat_target_reduced)\n",
    "        generation_loss = criterion(generated_text, flat_target_reduced)\n",
    "        kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        total_loss = reconstruction_loss + generation_loss + kl_divergence\n",
    "\n",
    "        # Retropropagación y actualización de pesos\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += total_loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_generado = vae.forward(input_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stranger als o by albert camu s\n"
     ]
    }
   ],
   "source": [
    "# Detokenización con spaCy\n",
    "texto_destokenizado = \" \".join(tokenized_corpus[0])\n",
    "doc = nlp.make_doc(texto_destokenizado)\n",
    "texto_destokenizado = \" \".join(token.text for token in doc)\n",
    "\n",
    "print(texto_destokenizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
